{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RflcvX_AT1EP"
      },
      "outputs": [],
      "source": [
        "## requirements\n",
        "import argparse\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "import random\n",
        "import torchvision.transforms.functional as TF\n",
        "from torchvision import transforms\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm, trange\n",
        "!pip install medpy\n",
        "import medpy.metric.binary as bin\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PTtEnsRN9N_a"
      },
      "outputs": [],
      "source": [
        "## We first want to load our dataset and convert it to numpy\n",
        "\"\"\"\n",
        "data file has to be in image format such as jpeg, png etc..\n",
        "Not ready for numpy file yet.\n",
        "A User only needs to change their dataset path in local and set result path.\n",
        "YOU MUST EITHER DOWNLOAD OUR TEST DATA OR HAVE YOUR OWN.\n",
        "\"\"\"\n",
        "\n",
        "!gdown \"1wOzvgroIgpEA9kaYfbz0Q3vUL5GY1my9&confirm=t\" # Model weight file, takes about 20 secs, file will be stored under content\n",
        "!mkdir result\n",
        "!mkdir test\n",
        "data_path = '/content/test'\n",
        "result_dir = '/content/result'\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GqNCCH5-Ufbh"
      },
      "outputs": [],
      "source": [
        "## implement model\n",
        "class Residual_block_3(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(Residual_block_3, self).__init__()\n",
        "        layers = []\n",
        "        layers += [nn.Conv2d(in_channels=in_channels, out_channels=out_channels,\n",
        "                                kernel_size=3, stride=1, padding=1,\n",
        "                                bias=True)]\n",
        "        layers += [nn.InstanceNorm2d(num_features=out_channels)]\n",
        "        layers += [nn.ReLU()]\n",
        "        layers += [nn.Conv2d(in_channels=out_channels, out_channels=out_channels,\n",
        "                                kernel_size=3, stride=1, padding=1,\n",
        "                                bias=True)]\n",
        "        layers += [nn.InstanceNorm2d(num_features=out_channels)]\n",
        "        layers += [nn.ReLU()]\n",
        "\n",
        "        self.conv = nn.Sequential(*layers)\n",
        "\n",
        "        skips = []\n",
        "        skips += [nn.Conv2d(in_channels=in_channels, out_channels=out_channels,\n",
        "                            kernel_size=3, stride=1, padding=1,\n",
        "                            bias=True)]\n",
        "        skips += [nn.InstanceNorm2d(num_features=out_channels)]\n",
        "\n",
        "        self.skip = nn.Sequential(*skips)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x) + self.skip(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Residual_block_7(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(Residual_block_7, self).__init__()\n",
        "        layers = []\n",
        "        layers += [nn.Conv2d(in_channels=in_channels, out_channels=out_channels,\n",
        "                                kernel_size=7, stride=1, padding=3,\n",
        "                                bias=True)]\n",
        "        layers += [nn.InstanceNorm2d(num_features=out_channels)]\n",
        "        layers += [nn.ReLU()]\n",
        "        layers += [nn.Conv2d(in_channels=out_channels, out_channels=out_channels,\n",
        "                                kernel_size=7, stride=1, padding=3,\n",
        "                                bias=True)]\n",
        "        layers += [nn.InstanceNorm2d(num_features=out_channels)]\n",
        "        layers += [nn.ReLU()]\n",
        "\n",
        "        self.conv = nn.Sequential(*layers)\n",
        "\n",
        "        skips = []\n",
        "        skips += [nn.Conv2d(in_channels=in_channels, out_channels=out_channels,\n",
        "                            kernel_size=7, stride=1, padding=3,\n",
        "                            bias=True)]\n",
        "        skips += [nn.InstanceNorm2d(num_features=out_channels)]\n",
        "\n",
        "        self.skip = nn.Sequential(*skips)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x) + self.skip(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Residual_block(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(Residual_block, self).__init__()\n",
        "        self.x3 = Residual_block_3(in_channels, out_channels)\n",
        "        self.x7 = Residual_block_7(in_channels, out_channels)\n",
        "\n",
        "        self.conv = nn.Conv2d(out_channels * 2, out_channels, kernel_size=1, stride=1, padding=0, bias=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x3 = self.x3(x)\n",
        "        x7 = self.x7(x)\n",
        "\n",
        "        x = torch.cat((x3, x7), dim=1)\n",
        "        x = self.conv(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "class ResUNet_MS(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ResUNet_MS, self).__init__()\n",
        "\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "        self.enc1_1 = Residual_block(in_channels=1, out_channels=64)\n",
        "\n",
        "        self.enc2_1 = Residual_block(in_channels=64, out_channels=128)\n",
        "\n",
        "        self.enc3_1 = Residual_block(in_channels=128, out_channels=256)\n",
        "\n",
        "        self.enc4_1 = Residual_block(in_channels=256, out_channels=512)\n",
        "\n",
        "        self.enc5_1 = Residual_block(in_channels=512, out_channels=1024)\n",
        "\n",
        "        self.unpool5 = nn.ConvTranspose2d(in_channels=1024, out_channels=512,\n",
        "                                        kernel_size=2, stride=2, padding=0, bias=True)\n",
        "        self.dec5_1 = Residual_block(in_channels=1024, out_channels=512)\n",
        "\n",
        "        self.unpool4 = nn.ConvTranspose2d(in_channels=512, out_channels=256,\n",
        "                                          kernel_size=2, stride=2, padding=0, bias=True)\n",
        "        self.dec4_1 = Residual_block(in_channels=512, out_channels=256)\n",
        "\n",
        "        self.unpool3 = nn.ConvTranspose2d(in_channels=256, out_channels=128,\n",
        "                                          kernel_size=2, stride=2, padding=0, bias=True)\n",
        "        self.dec3_1 = Residual_block(in_channels=256, out_channels=128)\n",
        "\n",
        "        self.unpool2 = nn.ConvTranspose2d(in_channels=128, out_channels=64,\n",
        "                                          kernel_size=2, stride=2, padding=0, bias=True)\n",
        "        self.dec2_1 = Residual_block(in_channels=128, out_channels=64)\n",
        "\n",
        "\n",
        "        self.fc = nn.Conv2d(in_channels=64, out_channels=1, kernel_size=1, stride=1, padding=0, bias=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        enc1_1 = self.enc1_1(x)\n",
        "\n",
        "        pool2 = self.pool(enc1_1)\n",
        "        enc2_1 = self.enc2_1(pool2)\n",
        "\n",
        "        pool3 = self.pool(enc2_1)\n",
        "        enc3_1 = self.enc3_1(pool3)\n",
        "\n",
        "        pool4 = self.pool(enc3_1)\n",
        "        enc4_1 = self.enc4_1(pool4)\n",
        "\n",
        "        pool5 = self.pool(enc4_1)\n",
        "        enc5_1 = self.enc5_1(pool5)\n",
        "\n",
        "        unpool5 = self.unpool5(enc5_1)\n",
        "        cat5 = torch.cat((unpool5, enc4_1), dim=1)\n",
        "        dec5_1 = self.dec5_1(cat5)\n",
        "\n",
        "        unpool4 = self.unpool4(dec5_1)\n",
        "        cat4 = torch.cat((unpool4, enc3_1), dim=1)\n",
        "        dec4_1 = self.dec4_1(cat4)\n",
        "\n",
        "        unpool3 = self.unpool3(dec4_1)\n",
        "        cat3 = torch.cat((unpool3, enc2_1), dim=1)\n",
        "        dec3_1 = self.dec3_1(cat3)\n",
        "\n",
        "        unpool2 = self.unpool2(dec3_1)\n",
        "        cat2 = torch.cat((unpool2, enc1_1), dim=1)\n",
        "        dec2_1 = self.dec2_1(cat2)\n",
        "\n",
        "        x = self.fc(dec2_1)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xf9SbZB2Vj_h"
      },
      "outputs": [],
      "source": [
        "## we would have to transform data if image size is too large\n",
        "class Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, data_dir):\n",
        "        self.data_dir = data_dir\n",
        "\n",
        "        lst_data = os.listdir(self.data_dir)\n",
        "\n",
        "        lst_input = [f for f in lst_data if f.startswith('input')]\n",
        "\n",
        "        lst_input.sort()\n",
        "\n",
        "        self.lst_input = lst_input\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.lst_input)\n",
        "\n",
        "    # for test\n",
        "    def test_transform(self, image):\n",
        "        # Transform to tensor\n",
        "        image = TF.to_tensor(image)\n",
        "\n",
        "        image = TF.normalize(image, 0.5, 0.5)\n",
        "\n",
        "        return image\n",
        "\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        p = os.path.join(self.data_dir, self.lst_input[index])\n",
        "\n",
        "        if p.endswith('npy'):\n",
        "          input = np.load(p)\n",
        "        else:\n",
        "          input = cv2.imread(os.path.join(self.data_dir, self.lst_input[index]), 0)\n",
        "\n",
        "        input = input/255.0\n",
        "\n",
        "        if input.ndim == 2:\n",
        "            input = input[:, :, np.newaxis]\n",
        "\n",
        "        # resize\n",
        "        # input = cv2.resize(input, (512,512), interpolation=cv2.INTER_AREA)\n",
        "\n",
        "        input = self.test_transform(input)\n",
        "\n",
        "        return input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dRBv95mxbNWy"
      },
      "outputs": [],
      "source": [
        "## pp\n",
        "def draw_contour(args: np.ndarray):\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (7,7))\n",
        "\n",
        "    pred= args\n",
        "\n",
        "    pred = pred // 255\n",
        "\n",
        "    # erase metric bar\n",
        "    pred[1080:, 1400:] = 0\n",
        "\n",
        "    o = np.uint8(pred)\n",
        "    contours, hie= cv2.findContours(o, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "\n",
        "    r = cv2.fillPoly(o, pts=contours, color=(255,255,255))\n",
        "\n",
        "    o = cv2.morphologyEx(r, cv2.MORPH_OPEN, kernel, iterations=2)\n",
        "\n",
        "    pp = o\n",
        "\n",
        "    o = np.uint8(o//255)\n",
        "\n",
        "    contours, hie= cv2.findContours(o, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    img_contour = cv2.drawContours(o, contours, -1, color=(255, 255, 255), thickness=5)\n",
        "\n",
        "    return img_contour, contours, hie, pp\n",
        "\n",
        "\n",
        "\n",
        "def analysis(img_contour, contours, hie):\n",
        "    info = {}\n",
        "    c = contours\n",
        "    c_im = img_contour\n",
        "    for i, x in enumerate(c):\n",
        "        tmp = {}\n",
        "        M = cv2.moments(x)\n",
        "\n",
        "        area = M['m00']\n",
        "        if area == 0.0:\n",
        "            continue\n",
        "\n",
        "        cX = int(M['m10'] / M['m00'])\n",
        "        cY = int(M['m01'] / M['m00'])\n",
        "\n",
        "\n",
        "        _,radius = cv2.minEnclosingCircle(x)\n",
        "        _, (minorAxisLength, majorAxisLength), angle = cv2.fitEllipse(x)\n",
        "\n",
        "        a = majorAxisLength / 2\n",
        "        b = minorAxisLength / 2\n",
        "\n",
        "        Eccentricity = round(np.sqrt(pow(a, 2) - pow(b, 2))/a, 2)\n",
        "\n",
        "        radius = int(radius)\n",
        "        diameter_in_pixels = radius * 2\n",
        "\n",
        "        cv2.putText(c_im, text=str(i+1), org=(cX, cY), fontFace= cv2.FONT_HERSHEY_SIMPLEX, fontScale=0.5, color=(255,255,255),\n",
        "                thickness=1, lineType=cv2.LINE_AA)\n",
        "        tmp[\"Area\"] = area\n",
        "        tmp[\"Diameter\"] = diameter_in_pixels\n",
        "        tmp[\"majorAxisLength\"] = np.round(majorAxisLength, 2)\n",
        "        tmp[\"minorAxisLength\"] = np.round(minorAxisLength,2)\n",
        "        tmp[\"Eccentricity\"] = Eccentricity\n",
        "        tmp[\"Perimeter\"] = np.round(cv2.arcLength(x, True),2)\n",
        "        info[i+1] = tmp\n",
        "\n",
        "\n",
        "    return info, c_im"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "McT3j-3MT-0V"
      },
      "outputs": [],
      "source": [
        "## define parameters\n",
        "## pretrained_model = final_model.pth\n",
        "# pretrained_model = torch.load('/content/drive/Shareddrives/오가노이드_AI_영상/organoid/chk/final_model.pth')\n",
        "\n",
        "map_location=torch.device ('cpu')\n",
        "device = torch.device ('cpu')\n",
        "pretrained _model = torch. load ('/content/orgaextractor.pth', map_location=device)\n",
        "\n",
        "model = ResUNet_MS().to(device)\n",
        "model = nn.DataParallel(module=model).to(device)\n",
        "model.load_state_dict(pretrained_model)\n",
        "# model.load_state_dict(pretrained_model['optim'], strict=False)\n",
        "\n",
        "batch_size = 2\n",
        "\n",
        "fn_tonumpy = lambda x: x.to('cpu').detach().numpy().transpose(0, 2, 3, 1)\n",
        "fn_denorm = lambda x, mean, std: (x * std) + mean\n",
        "fn_class = lambda x: 1.0 * (x > 0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PlkBwBVLaLsb"
      },
      "outputs": [],
      "source": [
        "## dataloader\n",
        "dataset_test = Dataset(data_dir=data_path)\n",
        "loader_test = DataLoader(dataset_test, batch_size=batch_size, shuffle=False)\n",
        "num_data_test = len(dataset_test)\n",
        "num_batch_test = np.ceil(num_data_test / batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E90F9XUsakw4"
      },
      "outputs": [],
      "source": [
        "## inference\n",
        "\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "amp_grad_scaler = GradScaler()\n",
        "\n",
        "# create result folder if not exists\n",
        "if not os.path.exists(os.path.join(result_dir, 'png')):\n",
        "        os.mkdir(os.path.join(result_dir, 'png'))\n",
        "        os.mkdir(os.path.join(result_dir, 'numpy'))\n",
        "\n",
        "# Setting Excel writer\n",
        "path = os.path.join(result_dir, 'analysis.xlsx')\n",
        "writer = pd.ExcelWriter(path, engine = 'openpyxl')\n",
        "\n",
        "with torch.no_grad():\n",
        "      model.eval()\n",
        "      # loss_arr = []\n",
        "      for batch, data in enumerate(loader_test, 1):\n",
        "      # for data in loader_test:\n",
        "          input = data.to(device, dtype=torch.float)\n",
        "          # label = data[1].to(device, dtype=torch.float)\n",
        "\n",
        "          with autocast():\n",
        "            output = model(input)\n",
        "\n",
        "          # label = fn_tonumpy(label)\n",
        "          input = fn_tonumpy(fn_denorm(input, mean=0.5, std=0.5))\n",
        "          output = fn_tonumpy(fn_class(output))\n",
        "\n",
        "          for j in range(input.shape[0]):\n",
        "\n",
        "              id = batch_size * (batch - 1) + j\n",
        "\n",
        "              # plt.imsave(os.path.join(result_dir, 'png', f'label_{id}.png'), label[j].squeeze(), cmap='gray')\n",
        "              plt.imsave(os.path.join(result_dir, 'png', f'input_{id}.png'), input[j].squeeze(), cmap='gray')\n",
        "              plt.imsave(os.path.join(result_dir, 'png', f'output_{id}.png'), output[j].squeeze(), cmap='gray')\n",
        "\n",
        "              # reread output due to cv2 type\n",
        "              o = os.path.join(result_dir, 'png', f'output_{id}.png')\n",
        "              o = cv2.imread(o, 0)\n",
        "              img_contour, contour, hie, pp = draw_contour(o)\n",
        "              info, c_im = analysis(img_contour, contour, hie)\n",
        "              df = pd.DataFrame(info)\n",
        "              df_t = df.transpose()\n",
        "              df_t.to_excel(writer, sheet_name=f'contour_{id}')\n",
        "              # print(c_im.shape)\n",
        "              plt.imsave(os.path.join(result_dir, 'png', f'contour_{id}.png'), img_contour, cmap='gray')\n",
        "              plt.imsave(os.path.join(result_dir, 'png', f'pp_{id}.png'), pp, cmap='gray')\n",
        "\n",
        "              # np.save(os.path.join(result_dir, 'numpy', f'label_{id}.npy'), label[j].squeeze())\n",
        "              np.save(os.path.join(result_dir, 'numpy', f'input_{id}.npy'), input[j].squeeze())\n",
        "              np.save(os.path.join(result_dir, 'numpy', f'output_{id}.npy'), output[j].squeeze())\n",
        "          writer.save()\n",
        "\n",
        "print('Image saved at: ', os.path.join(result_dir, 'png'))\n",
        "print('Numpy file saved at: ', os.path.join(result_dir, 'numpy'))\n",
        "print('--------------Orgaextractor--------------')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}